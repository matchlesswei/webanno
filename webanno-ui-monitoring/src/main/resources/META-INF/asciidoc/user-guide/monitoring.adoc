// Copyright 2015
// Ubiquitous Knowledge Processing (UKP) Lab and FG Language Technology
// Technische Universit√§t Darmstadt
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// 
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

[[sect_monitoring]]
== Monitoring ==

NOTE: This functionality is only available to *project managers* (managers of existing projects), 
      *curators*, and *administrators*. Curators and project managers only see projects in which
      they hold the respective roles.

As an administrator, you are able to observe the progress and document status of projects you are 
responsible for. Moreover, you are able to see the time of the last login of every user and observe the agreement between the annotators.
After clicking on *Monitoring* in the main menu, the following page is displayed:

image::monitoring1.png[align="center"]

In the right frame, the overall progress of all projects is displayed.
In the left frame one sees all projects, that one has an administrator role in.  
By clicking on one of the projects on the left, it may be selected and the following view is opened:

image::monitoring2.png[align="center"]

The percentual progress out of the workload for individual annotators may be viewed as well as the number of finished documents.

[[sect_monitoring_status]]

Below the document overview, a measuring for the inter-annotator-agreement can be selected by opening the *Measure* dropdown menu. Three different units of measurement are possible: https://en.wikipedia.org/wiki/Cohen%27s_kappa[Cohen's kappa] as implemented in
DKPro Statistics, link:https://en.wikipedia.org/wiki/Fleiss%27_kappa[Fleiss' kappa] and link:https://en.wikipedia.org/wiki/Krippendorff%27s_alpha[Krippendorff's alpha].
Below the *Measure* dropdown menu, an export format can be chosen. Currently, only link:https://en.wikipedia.org/wiki/Comma-separated_values[CSV] format is possible.

image::monitoring3.png[align="center"]

Above the *Measure* dropbdown menu, the *Feature* box allows the selection of layers for which an agreement shall be computed. Doubleclicking on a layer starts the computation of the agreement and an outline is shown to the left side of the box:

image::monitoring4.png[align="center"]

=== Document Status ===

The following table will explain the different symbols which explain the status of a document for a user and the described task.

[cols="1^,2", options="header"]
|===
| Symbol
| Meaning

| image:icon_new.png[]
| Annotation has not started yet

| image:icon_locked.png[]
| Document not available to user

| image:icon_annotation_in_progress.png[]
| Annotation is in progress

| image:icon_done.png[]
| Annotation is complete

| image:icon_curation_in_progress.png[]
| Curation is in progress
|===

You can also alter the document status of annotators. By clicking on the symbols you can change between *Done* and *In Progress*.
You can also alter between *New* and *Locked* status. 
The second column of the document status frame displays the status of the curation. 

As there is only one curator for one document, curation is not divided into individual curators.

Scrolling down, two further frames become visible. The left one, named *Layer*, allows you to chose a layer in which pairwise link:https://en.wikipedia.org/wiki/Cohen%27s_kappa[kappa agreement] between annotators will be calculated.

image::monitoring_agreement.jpg[align="center"]

[[sect_monitoring_agreement]]
=== Agreement ===

Agreement can be inspected on a per-feature basis and is calculated pair-wise between all 
annotators across all documents.

The first time a feature is selected for agreement inspection, it takes a moment to calculate the
differences between the annotated documents. Switching between different features subsequently
is much faster.

Agreement is calculated in two steps:

. *Generation of positions and configuration sets* - all documents are scanned for annotations and 
   annotations located at the same positions are collected in configuration sets. To determine if
   two annotations are at the same position, different approaches are used depending on the layer
   type. For a span layer, the begin and end offsets are used. For a relation layer, the begin and end
   offsets of the source and target annotation are used. Chains are currently not supported. 
. *Calculation of pairwise agreement* - based on the generated configuration sets, agreement is calculated.
  There are two cases where a configuration set may be omitted from the pairwise agreement calculation:
.. one of the users did not make an annotation at the position;
.. one or both of the users did not assign a value to the feature on which agreement is calculated
   at the position.

The lower part of the agreement matrix displays how many configuration sets were used to calculate
agreement and how many were found in total. The upper part of the agreement matrix displays the
pairwise Cohen's kappa scores.

The agreement calculations considers an unset feature (with a `null` value) to be equivalent to a
feature with the value of an empty string. Empty strings are considered valid labels and are not
excluded from agreement calculation.

Annotations for a given position are considered complete when both annotators have made an
annotation. Unless the agreement measure supports `null` values (i.e. missing annotations),
incomplete annotations are implicitly excluded from the agreement calculation. If the agreement
measure does support incomplete annotations, then excluding them or not is the users' choice.

.Possible combinations for agreement
|====
| Feature value annotator 1 | Feature value annotator 2 | Agreement | Complete

| `X`           
| `X`
| yes
| yes

| `X`           
| `Y`
| no
| yes

| *no annotation*           
| `Y`
| no
| no

| *empty*           
| `Y`
| no
| yes

| *empty*           
| *empty*
| yes
| yes

| *null*
| *empty*
| yes
| yes

| *empty*           
| *no annotation*
| no
| no

|====

  
CAUTION: Multiple interpretations in the form of stacked annotations are not supported in the agreement 
      calculation! This also includes relations for which source or targets spans are stacked.

